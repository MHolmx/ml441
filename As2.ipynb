{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3d85509-e1fd-44f0-802f-0ca437864f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from joblib import parallel as joblib_parallel\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, StratifiedShuffleSplit, GridSearchCV,\n",
    "    RandomizedSearchCV, ParameterGrid\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, make_scorer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ee9504a-22c8-4ecc-bb77-48643e65a21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (581012, 59)\n",
      "\n",
      "Missing values per column:\n",
      "Slope    0.05129\n",
      "dtype: float64\n",
      "\n",
      "Cardinality per column:\n",
      "Observation_ID                             1\n",
      "Soil_Type14                                2\n",
      "Soil_Type9                                 2\n",
      "Soil_Type10                                2\n",
      "Soil_Type11                                2\n",
      "Soil_Type12                                2\n",
      "Soil_Type13                                2\n",
      "Soil_Type15                                2\n",
      "Soil_Type16                                2\n",
      "Soil_Type17                                2\n",
      "Soil_Type18                                2\n",
      "Soil_Type19                                2\n",
      "Soil_Type20                                2\n",
      "Soil_Type21                                2\n",
      "Soil_Type22                                2\n",
      "Soil_Type23                                2\n",
      "Soil_Type24                                2\n",
      "Soil_Type25                                2\n",
      "Soil_Type26                                2\n",
      "Soil_Type27                                2\n",
      "Soil_Type8                                 2\n",
      "Soil_Type28                                2\n",
      "Soil_Type7                                 2\n",
      "Soil_Type5                                 2\n",
      "Soil_Type40                                2\n",
      "Soil_Type39                                2\n",
      "Soil_Type38                                2\n",
      "Soil_Type37                                2\n",
      "Soil_Type36                                2\n",
      "Soil_Type35                                2\n",
      "Soil_Type34                                2\n",
      "Soil_Type33                                2\n",
      "Soil_Type32                                2\n",
      "Soil_Type31                                2\n",
      "Soil_Type30                                2\n",
      "Wilderness_Area1                           2\n",
      "Wilderness_Area2                           2\n",
      "Wilderness_Area3                           2\n",
      "Wilderness_Area4                           2\n",
      "Soil_Type1                                 2\n",
      "Soil_Type2                                 2\n",
      "Soil_Type3                                 2\n",
      "Soil_Type4                                 2\n",
      "Soil_Type6                                 2\n",
      "Soil_Type29                                2\n",
      "Cover_Type                                 7\n",
      "Slope                                     67\n",
      "Hillshade_Noon                           185\n",
      "Hillshade_9am                            207\n",
      "Hillshade_3pm                            255\n",
      "Aspect                                   361\n",
      "Horizontal_Distance_To_Hydrology         576\n",
      "Vertical_Distance_To_Hydrology           700\n",
      "Elevation                               1978\n",
      "Horizontal_Distance_To_Roadways         5785\n",
      "Horizontal_Distance_To_Fire_Points      5827\n",
      "Facet                                 576048\n",
      "Inclination                           580937\n",
      "Water_Level                           581012\n",
      "dtype: int64\n",
      "\n",
      "Top correlations:\n",
      "Aspect            Facet               0.999998\n",
      "Wilderness_Area1  Wilderness_Area3    0.793593\n",
      "Hillshade_9am     Hillshade_3pm       0.780296\n",
      "Aspect            Hillshade_3pm       0.646944\n",
      "Facet             Hillshade_3pm       0.646941\n",
      "Elevation         Wilderness_Area4    0.619374\n",
      "Hillshade_Noon    Hillshade_3pm       0.594274\n",
      "Aspect            Hillshade_9am       0.579273\n",
      "Facet             Hillshade_9am       0.579270\n",
      "Wilderness_Area1  Soil_Type29         0.550549\n",
      "dtype: float64\n",
      "\n",
      "Column 'Soil_Type1' has non-numeric entries, e.g.:\n",
      "Soil_Type1\n",
      "positive    577981\n",
      "negative      3031\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric range differences:\n",
      "Elevation: min=2054195, max=4263090, mean=3270098.6571017466\n",
      "Aspect: min=0, max=360, mean=155.65680743254873\n",
      "Facet: min=0.0, max=903.4134047, mean=389.9193336298215\n",
      "Slope: min=0.0, max=66.0, mean=14.103737812417128\n",
      "Inclination: min=-0.999998898, max=0.999991982, mean=-0.00048448432609894443\n",
      "Horizontal_Distance_To_Hydrology: min=0, max=374289909, mean=5062.485785147294\n",
      "Vertical_Distance_To_Hydrology: min=-173, max=601, mean=46.418855376481034\n",
      "Horizontal_Distance_To_Roadways: min=0, max=7117, mean=2350.1466114297123\n",
      "Hillshade_9am: min=0, max=254, mean=212.14604861861716\n",
      "Hillshade_Noon: min=0, max=254, mean=223.31871630878535\n",
      "Hillshade_3pm: min=0, max=254, mean=142.52826275533036\n",
      "Horizontal_Distance_To_Fire_Points: min=0, max=7173, mean=1980.2912263430014\n",
      "Wilderness_Area1: min=0, max=1, mean=0.4488650836815763\n",
      "Wilderness_Area2: min=0, max=1, mean=0.051434393781884025\n",
      "Wilderness_Area3: min=0, max=1, mean=0.4360736094951567\n",
      "Wilderness_Area4: min=0, max=1, mean=0.06362691304138296\n",
      "Soil_Type2: min=0, max=1, mean=0.01295153972723455\n",
      "Soil_Type3: min=0, max=1, mean=0.008301033369362424\n",
      "Soil_Type4: min=0, max=1, mean=0.021335187569275677\n",
      "Soil_Type5: min=0, max=1, mean=0.0027486523514144287\n",
      "Soil_Type6: min=0, max=1, mean=0.011316461622135171\n",
      "Soil_Type7: min=0, max=1, mean=0.00018071915898466812\n",
      "Soil_Type8: min=0, max=1, mean=0.00030808313769767234\n",
      "Soil_Type9: min=0, max=1, mean=0.001974141670051565\n",
      "Soil_Type10: min=0, max=1, mean=0.056167514612434855\n",
      "Soil_Type11: min=0, max=1, mean=0.0213592834571403\n",
      "Soil_Type12: min=0, max=1, mean=0.05158413251361418\n",
      "Soil_Type13: min=0, max=1, mean=0.030001101526302382\n",
      "Soil_Type14: min=0, max=1, mean=0.0010309597736363448\n",
      "Soil_Type15: min=0, max=1, mean=5.163404542419089e-06\n",
      "Soil_Type16: min=0, max=1, mean=0.00489662864106077\n",
      "Soil_Type17: min=0, max=1, mean=0.005889723448052708\n",
      "Soil_Type18: min=0, max=1, mean=0.0032684350753512835\n",
      "Soil_Type19: min=0, max=1, mean=0.006920683221689053\n",
      "Soil_Type20: min=0, max=1, mean=0.015935987552752783\n",
      "Soil_Type21: min=0, max=1, mean=0.001442311002182399\n",
      "Soil_Type22: min=0, max=1, mean=0.05743943326471743\n",
      "Soil_Type23: min=0, max=1, mean=0.09939897971126242\n",
      "Soil_Type24: min=0, max=1, mean=0.03662230728453113\n",
      "Soil_Type25: min=0, max=1, mean=0.0008158179177022161\n",
      "Soil_Type26: min=0, max=1, mean=0.004456018120107674\n",
      "Soil_Type27: min=0, max=1, mean=0.0018691524443557104\n",
      "Soil_Type28: min=0, max=1, mean=0.0016281935657094862\n",
      "Soil_Type29: min=0, max=1, mean=0.19835562776672427\n",
      "Soil_Type30: min=0, max=1, mean=0.05192663834826131\n",
      "Soil_Type31: min=0, max=1, mean=0.04417464699524278\n",
      "Soil_Type32: min=0, max=1, mean=0.09039228105443606\n",
      "Soil_Type33: min=0, max=1, mean=0.07771612290279718\n",
      "Soil_Type34: min=0, max=1, mean=0.0027727482392790512\n",
      "Soil_Type35: min=0, max=1, mean=0.0032546659965714993\n",
      "Soil_Type36: min=0, max=1, mean=0.00020481504684929054\n",
      "Soil_Type37: min=0, max=1, mean=0.0005128981845469629\n",
      "Soil_Type38: min=0, max=1, mean=0.026803232979697493\n",
      "Soil_Type39: min=0, max=1, mean=0.02376198770421265\n",
      "Soil_Type40: min=0, max=1, mean=0.01505992991538901\n",
      "Water_Level: min=2, max=581013, mean=290507.5\n",
      "Observation_ID: min=1, max=1, mean=1.0\n",
      "Cover_Type: min=1, max=7, mean=2.051470537613681\n",
      "\n",
      "Potential outliers by column:\n",
      "Elevation: 15569 potential outliers\n",
      "Slope: 15308 potential outliers\n",
      "Horizontal_Distance_To_Hydrology: 14582 potential outliers\n",
      "Vertical_Distance_To_Hydrology: 31463 potential outliers\n",
      "Horizontal_Distance_To_Roadways: 669 potential outliers\n",
      "Hillshade_9am: 17433 potential outliers\n",
      "Hillshade_Noon: 15672 potential outliers\n",
      "Hillshade_3pm: 7832 potential outliers\n",
      "Horizontal_Distance_To_Fire_Points: 31157 potential outliers\n",
      "Wilderness_Area2: 29884 potential outliers\n",
      "Wilderness_Area4: 36968 potential outliers\n",
      "Soil_Type2: 7525 potential outliers\n",
      "Soil_Type3: 4823 potential outliers\n",
      "Soil_Type4: 12396 potential outliers\n",
      "Soil_Type5: 1597 potential outliers\n",
      "Soil_Type6: 6575 potential outliers\n",
      "Soil_Type7: 105 potential outliers\n",
      "Soil_Type8: 179 potential outliers\n",
      "Soil_Type9: 1147 potential outliers\n",
      "Soil_Type10: 32634 potential outliers\n",
      "Soil_Type11: 12410 potential outliers\n",
      "Soil_Type12: 29971 potential outliers\n",
      "Soil_Type13: 17431 potential outliers\n",
      "Soil_Type14: 599 potential outliers\n",
      "Soil_Type15: 3 potential outliers\n",
      "Soil_Type16: 2845 potential outliers\n",
      "Soil_Type17: 3422 potential outliers\n",
      "Soil_Type18: 1899 potential outliers\n",
      "Soil_Type19: 4021 potential outliers\n",
      "Soil_Type20: 9259 potential outliers\n",
      "Soil_Type21: 838 potential outliers\n",
      "Soil_Type22: 33373 potential outliers\n",
      "Soil_Type23: 57752 potential outliers\n",
      "Soil_Type24: 21278 potential outliers\n",
      "Soil_Type25: 474 potential outliers\n",
      "Soil_Type26: 2589 potential outliers\n",
      "Soil_Type27: 1086 potential outliers\n",
      "Soil_Type28: 946 potential outliers\n",
      "Soil_Type29: 115247 potential outliers\n",
      "Soil_Type30: 30170 potential outliers\n",
      "Soil_Type31: 25666 potential outliers\n",
      "Soil_Type32: 52519 potential outliers\n",
      "Soil_Type33: 45154 potential outliers\n",
      "Soil_Type34: 1611 potential outliers\n",
      "Soil_Type35: 1891 potential outliers\n",
      "Soil_Type36: 119 potential outliers\n",
      "Soil_Type37: 298 potential outliers\n",
      "Soil_Type38: 15573 potential outliers\n",
      "Soil_Type39: 13806 potential outliers\n",
      "Soil_Type40: 8750 potential outliers\n",
      "Cover_Type: 50117 potential outliers\n",
      "\n",
      "Target 'Cover_Type' distribution:\n",
      "Cover_Type\n",
      "2    0.487599\n",
      "1    0.364605\n",
      "3    0.061537\n",
      "7    0.035300\n",
      "6    0.029891\n",
      "5    0.016339\n",
      "4    0.004728\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"forestCover.csv\", na_values=[\"?\"])\n",
    "\n",
    "# --- 1. Shape ---\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "# --- 2. Missing values ---\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(100 *(df.isna().sum()[df.isna().sum() > 0] / df.shape[0]))\n",
    "\n",
    "# --- 3. Cardinality (unique values) ---\n",
    "print(\"\\nCardinality per column:\")\n",
    "card = df.nunique()\n",
    "print(card.sort_values())\n",
    "\n",
    "# --- 4. Correlation check (numeric only) ---\n",
    "print(\"\\nTop correlations:\")\n",
    "corr = df.corr(numeric_only=True).abs()\n",
    "high_corr = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "print(high_corr.stack().sort_values(ascending=False).head(10))\n",
    "\n",
    "# --- 5. Check for invalid / non-numeric in supposed numeric columns ---\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        print(f\"\\nColumn '{col}' has non-numeric entries, e.g.:\")\n",
    "        print(df[col].value_counts().head())\n",
    "\n",
    "# --- 6. Range differences ---\n",
    "print(\"\\nNumeric range differences:\")\n",
    "for col in df.select_dtypes(include=[np.number]):\n",
    "    print(f\"{col}: min={df[col].min()}, max={df[col].max()}, mean={df[col].mean()}\")\n",
    "\n",
    "# --- 7. Outlier detection (simple IQR rule) ---\n",
    "print(\"\\nPotential outliers by column:\")\n",
    "for col in df.select_dtypes(include=[np.number]):\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    outliers = ((df[col] < (q1 - 1.5 * iqr)) | (df[col] > (q3 + 1.5 * iqr))).sum()\n",
    "    if outliers > 0:\n",
    "        print(f\"{col}: {outliers} potential outliers\")\n",
    "\n",
    "# --- 8. Target distribution ---\n",
    "target = df.columns[-1]\n",
    "print(f\"\\nTarget '{target}' distribution:\")\n",
    "print(df[target].value_counts(dropna=False, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8114e7c2-c687-4fcf-ba6e-f5a259653a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_ohe_dense():\n",
    "    params = inspect.signature(OneHotEncoder).parameters\n",
    "    if \"sparse_output\" in params:              # sklearn >= 1.2\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    else:                                      # sklearn < 1.2\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "# ---------- Load data ----------\n",
    "df = pd.read_csv(\"forestCover.csv\", na_values=[\"?\"])\n",
    "\n",
    "target_col = df.columns[-1]\n",
    "y = df[target_col]\n",
    "\n",
    "# ---------- Helper to resolve column names robustly ----------\n",
    "def find_col(df, candidates):\n",
    "    norm = {c.lower().replace(\" \", \"\").replace(\"_\", \"\"): c for c in df.columns}\n",
    "    for cand in candidates:\n",
    "        key = cand.lower().replace(\" \", \"\").replace(\"_\", \"\")\n",
    "        if key in norm:\n",
    "            return norm[key]\n",
    "    return None\n",
    "\n",
    "COL_ID          = find_col(df, [\"Observation ID\", \"ObservationID\", \"ObsID\", \"ID\"])\n",
    "COL_WATER       = find_col(df, [\"Water Level\", \"WaterLevel\"])\n",
    "COL_FACET       = find_col(df, [\"Facet\"])\n",
    "COL_ASPECT      = find_col(df, [\"Aspect\"])\n",
    "COL_INCLINATION = find_col(df, [\"Inclination\"])\n",
    "\n",
    "# ---------- kNN: apply ONLY the necessary transforms ----------\n",
    "# Drop: ID (unique), Water Level (constant), Facet (redundant with Aspect), Inclination (noise-only)\n",
    "to_drop_knn = [c for c in [COL_ID, COL_WATER, COL_FACET, COL_INCLINATION] if c in df.columns]\n",
    "X_knn_base = df.drop(columns=[target_col] + to_drop_knn)\n",
    "\n",
    "# Identify column types after drops\n",
    "numeric_cols_knn = X_knn_base.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols_knn = [c for c in X_knn_base.columns if c not in numeric_cols_knn]\n",
    "\n",
    "knn_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", RobustScaler())\n",
    "        ]), numeric_cols_knn),\n",
    "        (\"cat\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", make_ohe_dense())       # <-- changed here\n",
    "        ]), categorical_cols_knn)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "X_knn_ready = knn_preprocessor.fit_transform(X_knn_base)\n",
    "\n",
    "# ---------- Classification Trees: ONLY necessary transforms ----------\n",
    "# Drop: ID (unique), Water Level (constant). Keep Facet+Aspect (redundancy benign). Keep Inclination (noise tolerated).\n",
    "to_drop_tree = [c for c in [COL_ID, COL_WATER] if c in df.columns]\n",
    "X_tree_base = df.drop(columns=[target_col] + to_drop_tree)\n",
    "\n",
    "numeric_cols_tree = X_tree_base.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols_tree = [c for c in X_tree_base.columns if c not in numeric_cols_tree]\n",
    "\n",
    "tree_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "        ]), numeric_cols_tree),\n",
    "        (\"cat\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", make_ohe_dense()) \n",
    "        ]), categorical_cols_tree)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "X_tree_ready = tree_preprocessor.fit_transform(X_tree_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45cbc9f6-82a9-4d3c-992c-0d810e4c2d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN processed DataFrame:\n",
      "   num__Elevation  num__Aspect  num__Slope  \\\n",
      "0       -0.259887     0.193069   -0.777778   \n",
      "1       -1.333333     0.049505   -0.444444   \n",
      "2        0.189266     1.138614   -0.444444   \n",
      "3        0.096045     0.103960   -0.777778   \n",
      "4       -0.635593    -0.014851   -0.222222   \n",
      "\n",
      "   num__Horizontal_Distance_To_Hydrology  num__Vertical_Distance_To_Hydrology  \\\n",
      "0                               0.688406                             0.516129   \n",
      "1                              -0.681159                            -0.451613   \n",
      "2                               0.521739                            -0.241935   \n",
      "3                               0.105072                             0.322581   \n",
      "4                              -0.173913                            -0.177419   \n",
      "\n",
      "   num__Horizontal_Distance_To_Roadways  num__Hillshade_9am  \\\n",
      "0                              0.513051            0.212121   \n",
      "1                             -0.430693            0.515152   \n",
      "2                              0.502250           -0.333333   \n",
      "3                             -0.355536            0.303030   \n",
      "4                             -0.180918            0.606061   \n",
      "\n",
      "   num__Hillshade_Noon  num__Hillshade_3pm  \\\n",
      "0             0.666667            0.163265   \n",
      "1             0.458333           -0.204082   \n",
      "2            -0.041667            0.265306   \n",
      "3             0.583333            0.040816   \n",
      "4             0.250000           -0.387755   \n",
      "\n",
      "   num__Horizontal_Distance_To_Fire_Points  ...  num__Soil_Type33  \\\n",
      "0                                 0.429882  ...               0.0   \n",
      "1                                 0.061599  ...               0.0   \n",
      "2                                -0.927261  ...               0.0   \n",
      "3                                 0.455439  ...               0.0   \n",
      "4                                 0.738532  ...               0.0   \n",
      "\n",
      "   num__Soil_Type34  num__Soil_Type35  num__Soil_Type36  num__Soil_Type37  \\\n",
      "0               0.0               0.0               0.0               0.0   \n",
      "1               0.0               0.0               0.0               0.0   \n",
      "2               0.0               0.0               0.0               0.0   \n",
      "3               0.0               0.0               0.0               0.0   \n",
      "4               0.0               0.0               0.0               0.0   \n",
      "\n",
      "   num__Soil_Type38  num__Soil_Type39  num__Soil_Type40  \\\n",
      "0               0.0               0.0               0.0   \n",
      "1               0.0               0.0               0.0   \n",
      "2               0.0               0.0               0.0   \n",
      "3               0.0               0.0               0.0   \n",
      "4               0.0               0.0               0.0   \n",
      "\n",
      "   cat__Soil_Type1_negative  cat__Soil_Type1_positive  \n",
      "0                       0.0                       1.0  \n",
      "1                       0.0                       1.0  \n",
      "2                       0.0                       1.0  \n",
      "3                       0.0                       1.0  \n",
      "4                       0.0                       1.0  \n",
      "\n",
      "[5 rows x 55 columns]\n",
      "\n",
      "Tree processed DataFrame:\n",
      "   num__Elevation  num__Aspect  num__Facet  num__Slope  num__Inclination  \\\n",
      "0       3208920.0        166.0  415.394727         6.0          0.691628   \n",
      "1       2789020.0        137.0  343.302186         9.0          0.621245   \n",
      "2       3384615.0        357.0  894.231390         9.0         -0.266086   \n",
      "3       3348150.0        148.0  371.346939         6.0          0.786375   \n",
      "4       3061955.0        124.0  310.783430        11.0         -0.335685   \n",
      "\n",
      "   num__Horizontal_Distance_To_Hydrology  num__Vertical_Distance_To_Hydrology  \\\n",
      "0                                  408.0                                 62.0   \n",
      "1                                   30.0                                  2.0   \n",
      "2                                  362.0                                 15.0   \n",
      "3                                  247.0                                 50.0   \n",
      "4                                  170.0                                 19.0   \n",
      "\n",
      "   num__Horizontal_Distance_To_Roadways  num__Hillshade_9am  \\\n",
      "0                                3137.0               225.0   \n",
      "1                                1040.0               235.0   \n",
      "2                                3113.0               207.0   \n",
      "3                                1207.0               228.0   \n",
      "4                                1595.0               238.0   \n",
      "\n",
      "   num__Hillshade_Noon  ...  num__Soil_Type33  num__Soil_Type34  \\\n",
      "0                242.0  ...               0.0               0.0   \n",
      "1                237.0  ...               0.0               0.0   \n",
      "2                225.0  ...               0.0               0.0   \n",
      "3                240.0  ...               0.0               0.0   \n",
      "4                232.0  ...               0.0               0.0   \n",
      "\n",
      "   num__Soil_Type35  num__Soil_Type36  num__Soil_Type37  num__Soil_Type38  \\\n",
      "0               0.0               0.0               0.0               0.0   \n",
      "1               0.0               0.0               0.0               0.0   \n",
      "2               0.0               0.0               0.0               0.0   \n",
      "3               0.0               0.0               0.0               0.0   \n",
      "4               0.0               0.0               0.0               0.0   \n",
      "\n",
      "   num__Soil_Type39  num__Soil_Type40  cat__Soil_Type1_negative  \\\n",
      "0               0.0               0.0                       0.0   \n",
      "1               0.0               0.0                       0.0   \n",
      "2               0.0               0.0                       0.0   \n",
      "3               0.0               0.0                       0.0   \n",
      "4               0.0               0.0                       0.0   \n",
      "\n",
      "   cat__Soil_Type1_positive  \n",
      "0                       1.0  \n",
      "1                       1.0  \n",
      "2                       1.0  \n",
      "3                       1.0  \n",
      "4                       1.0  \n",
      "\n",
      "[5 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "knn_feature_names = knn_preprocessor.get_feature_names_out()\n",
    "X_knn_df = pd.DataFrame(X_knn_ready, columns=knn_feature_names, index=X_knn_base.index)\n",
    "\n",
    "print(\"kNN processed DataFrame:\")\n",
    "print(X_knn_df.head())\n",
    "\n",
    "tree_feature_names = tree_preprocessor.get_feature_names_out()\n",
    "X_tree_df = pd.DataFrame(X_tree_ready, columns=tree_feature_names, index=X_tree_base.index)\n",
    "\n",
    "print(\"\\nTree processed DataFrame:\")\n",
    "print(X_tree_df.head())#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "62b0e973-bcd2-4170-8e01-d2beec8652ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kNN GridSearch: 100%|██████████| 360/360 [12:58<00:00,  2.16s/fit]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best kNN params: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best kNN CV (F1-weighted): 0.8306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tree RandomSearch: 100%|██████████| 1200/1200 [00:33<00:00, 35.98fit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Tree params: {'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': 20, 'criterion': 'entropy', 'class_weight': None, 'ccp_alpha': 1e-05}\n",
      "Best Tree CV (F1-weighted): 0.7855\n",
      "\n",
      "== Final test (common split) ==\n",
      "kNN (final): Acc=0.9349, Prec=0.9349, Rec=0.9349, F1=0.9349\n",
      "Decision Tree (final): Acc=0.9139, Prec=0.9138, Rec=0.9139, F1=0.9138\n",
      "\n",
      "Confusion matrix (kNN):\n",
      "[[59371  3806     4     0    57    15   299]\n",
      " [ 3536 80614   232     2   305   259    43]\n",
      " [    1   231  9829    80    18   567     0]\n",
      " [    0     1   118   657     0    48     0]\n",
      " [   53   467    30     0  2274    22     2]\n",
      " [   16   232   524    34    13  4391     0]\n",
      " [  284    43     0     0     0     0  5826]]\n",
      "\n",
      "Confusion matrix (Tree):\n",
      "[[57861  5346     3     0    38     5   299]\n",
      " [ 5675 78565   219     0   327   165    40]\n",
      " [    3   312  9885    91    20   415     0]\n",
      " [    0     0    92   694     0    38     0]\n",
      " [   54   545    33     0  2193    20     3]\n",
      " [   20   226   463    43    17  4441     0]\n",
      " [  441    55     0     0     0     0  5657]]\n",
      "\n",
      "Per-class report (kNN):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.93      0.94     63552\n",
      "           2       0.94      0.95      0.95     84991\n",
      "           3       0.92      0.92      0.92     10726\n",
      "           4       0.85      0.80      0.82       824\n",
      "           5       0.85      0.80      0.82      2848\n",
      "           6       0.83      0.84      0.84      5210\n",
      "           7       0.94      0.95      0.95      6153\n",
      "\n",
      "    accuracy                           0.93    174304\n",
      "   macro avg       0.90      0.88      0.89    174304\n",
      "weighted avg       0.93      0.93      0.93    174304\n",
      "\n",
      "\n",
      "Per-class report (Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.91      0.91     63552\n",
      "           2       0.92      0.92      0.92     84991\n",
      "           3       0.92      0.92      0.92     10726\n",
      "           4       0.84      0.84      0.84       824\n",
      "           5       0.85      0.77      0.81      2848\n",
      "           6       0.87      0.85      0.86      5210\n",
      "           7       0.94      0.92      0.93      6153\n",
      "\n",
      "    accuracy                           0.91    174304\n",
      "   macro avg       0.89      0.88      0.88    174304\n",
      "weighted avg       0.91      0.91      0.91    174304\n",
      "\n",
      "\n",
      "=== kNN CV Results (mean ± std across 10 folds) ===\n",
      "                    mean     std\n",
      "fit_time          0.4791  0.0216\n",
      "score_time      785.4062  0.7192\n",
      "test_accuracy     0.9328  0.0012\n",
      "test_precision    0.9327  0.0012\n",
      "test_recall       0.9328  0.0012\n",
      "test_f1           0.9328  0.0012\n",
      "\n",
      "=== Decision Tree CV Results (mean ± std across 10 folds) ===\n",
      "                   mean     std\n",
      "fit_time        17.1054  0.0969\n",
      "score_time       0.0728  0.0072\n",
      "test_accuracy    0.9069  0.0027\n",
      "test_precision   0.9068  0.0026\n",
      "test_recall      0.9069  0.0027\n",
      "test_f1          0.9068  0.0027\n",
      "\n",
      "=== Paired tests across 10 CV folds (accuracy) ===\n",
      "Observed mean diff (kNN - Tree): 0.0259 ± 0.0027\n",
      "Paired t-test: t=30.421, p=2.194e-10\n",
      "Wilcoxon: W=0.000, p=1.953e-03\n",
      "\n",
      "=== Paired tests across 10 CV folds (f1) ===\n",
      "Observed mean diff (kNN - Tree): 0.0260 ± 0.0026\n",
      "Paired t-test: t=31.004, p=1.851e-10\n",
      "Wilcoxon: W=0.000, p=1.953e-03\n",
      "\n",
      "=== Paired tests across runs (accuracy) ===\n",
      "Observed mean diff (kNN - Tree): 0.0394 ± 0.0038\n",
      "Paired t-test: t=33.007, p=1.059e-10\n",
      "Wilcoxon: W=0.000, p=1.953e-03\n",
      "\n",
      "=== Paired tests across runs (f1) ===\n",
      "Observed mean diff (kNN - Tree): 0.0392 ± 0.0037\n",
      "Paired t-test: t=33.636, p=8.945e-11\n",
      "Wilcoxon: W=0.000, p=1.953e-03\n",
      "\n",
      "=== McNemar’s test (final test split) ===\n",
      "b01=6907, b10=10573, statistic=6907.0, p-value=2.242e-170\n",
      "\n",
      "=== Permutation test (accuracy, final test split) ===\n",
      "Observed diff: 0.0210\n",
      "p-value: 9.995e-04\n",
      "\n",
      "=== Bootstrap 95% CI for accuracy diff (kNN - Tree, final test split) ===\n",
      "[0.0196, 0.0224]\n",
      "\n",
      "Top kNN configs:\n",
      "     mean_test_score  std_test_score param_n_neighbors param_weights  \\\n",
      "25         0.830562        0.006461                 3      distance   \n",
      "27         0.829795        0.005375                 5      distance   \n",
      "29         0.827814        0.005486                 7      distance   \n",
      "31         0.824597        0.006088                 9      distance   \n",
      "13         0.822727        0.006623                 3      distance   \n",
      "15         0.822229        0.006709                 5      distance   \n",
      "24         0.821793        0.006327                 3       uniform   \n",
      "33         0.821273        0.005585                11      distance   \n",
      "17         0.818167        0.005913                 7      distance   \n",
      "35         0.817844        0.006849                13      distance   \n",
      "\n",
      "   param_metric param_p  \n",
      "25    manhattan     NaN  \n",
      "27    manhattan     NaN  \n",
      "29    manhattan     NaN  \n",
      "31    manhattan     NaN  \n",
      "13    euclidean     NaN  \n",
      "15    euclidean     NaN  \n",
      "24    manhattan     NaN  \n",
      "33    manhattan     NaN  \n",
      "17    euclidean     NaN  \n",
      "35    manhattan     NaN  \n",
      "\n",
      "Top Tree configs:\n",
      "      mean_test_score  std_test_score param_criterion param_max_depth  \\\n",
      "19          0.785477        0.008228         entropy              20   \n",
      "86          0.777602        0.007754         entropy              60   \n",
      "55          0.776859        0.006098         entropy            None   \n",
      "30          0.776195        0.006264         entropy              60   \n",
      "118         0.764482        0.004299         entropy              40   \n",
      "25          0.751523        0.005527            gini              30   \n",
      "18          0.751273        0.004835            gini              16   \n",
      "1           0.741082        0.006019            gini              16   \n",
      "81          0.716082        0.010918         entropy              80   \n",
      "16          0.714155        0.009293            gini             100   \n",
      "\n",
      "    param_min_samples_split param_min_samples_leaf param_max_features  \\\n",
      "19                        2                      2               None   \n",
      "86                       20                      5               None   \n",
      "55                       10                     10               None   \n",
      "30                       10                     10               None   \n",
      "118                       2                      5               None   \n",
      "25                        5                     20               None   \n",
      "18                        5                     20               None   \n",
      "1                         5                      5               None   \n",
      "81                       20                      2               log2   \n",
      "16                       50                     10               sqrt   \n",
      "\n",
      "    param_ccp_alpha param_class_weight  \n",
      "19          0.00001               None  \n",
      "86          0.00001               None  \n",
      "55           0.0001               None  \n",
      "30              0.0               None  \n",
      "118        0.000032           balanced  \n",
      "25         0.000316               None  \n",
      "18         0.000316               None  \n",
      "1               0.0           balanced  \n",
      "81           0.0001               None  \n",
      "16           0.0001               None  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "@contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    \"\"\"Patch joblib to report into tqdm progress bar.\"\"\"\n",
    "    OriginalBatchCompletionCallBack = joblib_parallel.BatchCompletionCallBack\n",
    "    class TqdmBatchCompletionCallBack(OriginalBatchCompletionCallBack):\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size) \n",
    "            return super().__call__(*args, **kwargs)\n",
    "    joblib_parallel.BatchCompletionCallBack = TqdmBatchCompletionCallBack\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib_parallel.BatchCompletionCallBack = OriginalBatchCompletionCallBack\n",
    "        tqdm_object.close()\n",
    "\n",
    "# =========================\n",
    "# 1) Configuration knobs\n",
    "# =========================\n",
    "RANDOM_SEED     = 42\n",
    "TEST_SIZE       = 0.30     # final, untouched test split\n",
    "TUNE_SIZE       = 30_000   #tuning subset size (from TRAIN ONLY)\n",
    "CV_FOLDS        = 10        # CV folds for both searches\n",
    "N_RUNS          = 10       # repeated independent runs for mean ± std\n",
    "RUN_SUBSET_SIZE = 75_000   # per-run subset size (independent from tuning subset)\n",
    "\n",
    "rng_global = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "# ===========================================================\n",
    "# 2) Common train/test split (works for BOTH feature spaces)\n",
    "# ===========================================================\n",
    "X_idx = np.arange(len(y))\n",
    "idx_train, idx_test, y_train, y_test = train_test_split(\n",
    "    X_idx, y, test_size=TEST_SIZE, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "\n",
    "X_knn_train = X_knn_df.iloc[idx_train]\n",
    "X_knn_test  = X_knn_df.iloc[idx_test]\n",
    "X_tree_train= X_tree_df.iloc[idx_train]\n",
    "X_tree_test = X_tree_df.iloc[idx_test]\n",
    "\n",
    "# ===========================================================\n",
    "# 3) Build a stratified tuning subset from TRAIN ONLY\n",
    "# ===========================================================\n",
    "if len(y_train) <= TUNE_SIZE:\n",
    "    tune_mask = np.arange(len(y_train))\n",
    "else:\n",
    "    sss_tune = StratifiedShuffleSplit(\n",
    "        n_splits=1,\n",
    "        test_size=(len(y_train) - TUNE_SIZE) / len(y_train),\n",
    "        random_state=RANDOM_SEED + 1\n",
    "    )\n",
    "    (tune_mask, _), = sss_tune.split(X_knn_train, y_train)\n",
    "\n",
    "X_knn_tune  = X_knn_train.iloc[tune_mask]\n",
    "X_tree_tune = X_tree_train.iloc[tune_mask]\n",
    "y_tune      = y_train.iloc[tune_mask]\n",
    "\n",
    "scorer = make_scorer(f1_score, average=\"weighted\", zero_division=0)\n",
    "\n",
    "# ============================================\n",
    "# 5) kNN: conditional grid + progress + search\n",
    "# ============================================\n",
    "knn = KNeighborsClassifier(algorithm=\"brute\")  \n",
    "knn_param_grid = [\n",
    "    {  # minkowski branch (uses p)\n",
    "        \"n_neighbors\": list(range(3, 14, 2)),       \n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"metric\": [\"minkowski\"],\n",
    "        \"p\": [3],\n",
    "    },\n",
    "    {  #euclidean/manhattan (no p)\n",
    "        \"n_neighbors\": list(range(3, 14, 2)),\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"metric\": [\"euclidean\", \"manhattan\"],\n",
    "    },\n",
    "]\n",
    "knn_grid = GridSearchCV(\n",
    "    estimator=knn,\n",
    "    param_grid=knn_param_grid,\n",
    "    scoring=scorer,\n",
    "    cv=CV_FOLDS,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "n_candidates_knn = sum(len(list(ParameterGrid(pg))) for pg in knn_param_grid)\n",
    "total_fits_knn   = n_candidates_knn * CV_FOLDS\n",
    "\n",
    "with tqdm(total=total_fits_knn, desc=\"kNN GridSearch\", unit=\"fit\") as pbar:\n",
    "    with tqdm_joblib(pbar):\n",
    "        knn_grid.fit(X_knn_tune, y_tune)\n",
    "\n",
    "print(\"\\nBest kNN params:\", knn_grid.best_params_)\n",
    "print(\"Best kNN CV (F1-weighted):\", round(knn_grid.best_score_, 4))\n",
    "\n",
    "# ===================================\n",
    "# 6) Decision Tree: randomized search\n",
    "# ===================================\n",
    "tree = DecisionTreeClassifier(random_state=RANDOM_SEED)\n",
    "tree_param_dist = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [None, 5, 8, 10, 12, 16, 20, 30, 40, 60, 80, 100],\n",
    "    \"min_samples_split\": [2, 5, 10, 20, 50],\n",
    "    \"min_samples_leaf\": [1, 2, 5, 10, 20, 100, 1000, 10000],\n",
    "    \"max_features\": [None, \"sqrt\", \"log2\"],\n",
    "    \"ccp_alpha\": np.concatenate(([0.0], np.logspace(-5, -1, 9))),\n",
    "    \"class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "tree_rand = RandomizedSearchCV(\n",
    "    estimator=tree,\n",
    "    param_distributions=tree_param_dist,\n",
    "    n_iter=120,         \n",
    "    scoring=scorer,\n",
    "    cv=CV_FOLDS,\n",
    "    random_state=RANDOM_SEED + 2,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "total_fits_tree = tree_rand.n_iter * CV_FOLDS\n",
    "\n",
    "with tqdm(total=total_fits_tree, desc=\"Tree RandomSearch\", unit=\"fit\") as pbar:\n",
    "    with tqdm_joblib(pbar):\n",
    "        tree_rand.fit(X_tree_tune, y_tune)\n",
    "\n",
    "print(\"\\nBest Tree params:\", tree_rand.best_params_)\n",
    "print(\"Best Tree CV (F1-weighted):\", round(tree_rand.best_score_, 4))\n",
    "\n",
    "# ==========================================================\n",
    "# 7) Refit best models on ALL TRAIN data (no test leakage)\n",
    "# ==========================================================\n",
    "best_knn = KNeighborsClassifier(algorithm=\"brute\", **{k: v for k, v in knn_grid.best_params_.items() if k != \"algorithm\"})\n",
    "best_knn.fit(X_knn_train, y_train)\n",
    "\n",
    "best_tree = DecisionTreeClassifier(random_state=RANDOM_SEED, **tree_rand.best_params_)\n",
    "best_tree.fit(X_tree_train, y_train)\n",
    "\n",
    "# ======================================\n",
    "# 8) Final evaluation on the TEST split\n",
    "# ======================================\n",
    "def evaluate(name, model, Xte, yte):\n",
    "    yhat = model.predict(Xte)\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"accuracy\": accuracy_score(yte, yhat),\n",
    "        \"precision\": precision_score(yte, yhat, average=\"weighted\", zero_division=0),\n",
    "        \"recall\": recall_score(yte, yhat, average=\"weighted\", zero_division=0),\n",
    "        \"f1\": f1_score(yte, yhat, average=\"weighted\", zero_division=0),\n",
    "        \"yhat\": yhat\n",
    "    }\n",
    "\n",
    "final_knn  = evaluate(\"kNN (final)\", best_knn,  X_knn_test,  y_test)\n",
    "final_tree = evaluate(\"Decision Tree (final)\", best_tree, X_tree_test, y_test)\n",
    "\n",
    "print(\"\\n== Final test (common split) ==\")\n",
    "for res in [final_knn, final_tree]:\n",
    "    print(f\"{res['name']}: Acc={res['accuracy']:.4f}, Prec={res['precision']:.4f}, Rec={res['recall']:.4f}, F1={res['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion matrix (kNN):\")\n",
    "print(confusion_matrix(y_test, final_knn[\"yhat\"]))\n",
    "print(\"\\nConfusion matrix (Tree):\")\n",
    "print(confusion_matrix(y_test, final_tree[\"yhat\"]))\n",
    "print(\"\\nPer-class report (kNN):\")\n",
    "print(classification_report(y_test, final_knn[\"yhat\"], zero_division=0))\n",
    "print(\"\\nPer-class report (Tree):\")\n",
    "print(classification_report(y_test, final_tree[\"yhat\"], zero_division=0))\n",
    "\n",
    "# ===========================================================\n",
    "# 9) Cross-validation for mean ± std (no leakage)\n",
    "# ===========================================================\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Define scorers\n",
    "scorers = {\n",
    "    \"accuracy\": make_scorer(accuracy_score),\n",
    "    \"precision\": make_scorer(precision_score, average=\"weighted\", zero_division=0),\n",
    "    \"recall\": make_scorer(recall_score, average=\"weighted\", zero_division=0),\n",
    "    \"f1\": make_scorer(f1_score, average=\"weighted\", zero_division=0),\n",
    "}\n",
    "\n",
    "# Run CV for kNN\n",
    "cv_knn = cross_validate(\n",
    "    best_knn, X_knn_train, y_train,\n",
    "    cv=CV_FOLDS,\n",
    "    scoring=scorers,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "# Run CV for Tree\n",
    "cv_tree = cross_validate(\n",
    "    best_tree, X_tree_train, y_train,\n",
    "    cv=CV_FOLDS,\n",
    "    scoring=scorers,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "def summarize_cv(cv_res, name):\n",
    "    df = pd.DataFrame(cv_res)\n",
    "    mean_std = df.agg([\"mean\",\"std\"]).round(4).T\n",
    "    print(f\"\\n=== {name} CV Results (mean ± std across {CV_FOLDS} folds) ===\")\n",
    "    print(mean_std)\n",
    "\n",
    "summarize_cv(cv_knn, \"kNN\")\n",
    "summarize_cv(cv_tree, \"Decision Tree\")\n",
    "\n",
    "# ---------------------------\n",
    "# 10) Aggregate Mean ± Std\n",
    "# ---------------------------\n",
    "def paired_tests(cv_a, cv_b, metric_key):\n",
    "    a = np.asarray(cv_a[f\"test_{metric_key}\"])\n",
    "    b = np.asarray(cv_b[f\"test_{metric_key}\"])\n",
    "    diff = a - b\n",
    "    t = ttest_rel(a, b)\n",
    "    try:\n",
    "        w = wilcoxon(a, b, zero_method=\"wilcox\")\n",
    "        w_str = f\"W={w.statistic:.3f}, p={w.pvalue:.3e}\"\n",
    "    except ValueError:\n",
    "        w_str = \"Wilcoxon skipped (all diffs zero)\"\n",
    "    print(f\"\\n=== Paired tests across {CV_FOLDS} CV folds ({metric_key}) ===\")\n",
    "    print(f\"Observed mean diff (kNN - Tree): {diff.mean():.4f} ± {diff.std(ddof=1):.4f}\")\n",
    "    print(f\"Paired t-test: t={t.statistic:.3f}, p={t.pvalue:.3e}\")\n",
    "    print(f\"Wilcoxon: {w_str}\")\n",
    "\n",
    "paired_tests(cv_knn, cv_tree, \"accuracy\")\n",
    "paired_tests(cv_knn, cv_tree, \"f1\")\n",
    "# ==========================================\n",
    "# 11) Paired tests across runs (kNN vs Tree)\n",
    "# ==========================================\n",
    "from scipy.stats import ttest_rel, wilcoxon\n",
    "\n",
    "def paired_vec(metric):\n",
    "    a = df_results.query(\"model=='kNN'\").sort_values(\"run\")[metric].to_numpy()\n",
    "    b = df_results.query(\"model=='Tree'\").sort_values(\"run\")[metric].to_numpy()\n",
    "    return a, b\n",
    "\n",
    "for metric in [\"accuracy\", \"f1\"]:\n",
    "    a, b = paired_vec(metric)\n",
    "    diff = a - b\n",
    "    t = ttest_rel(a, b)\n",
    "    try:\n",
    "        w = wilcoxon(a, b, zero_method=\"wilcox\")\n",
    "        w_str = f\"W={w.statistic:.3f}, p={w.pvalue:.3e}\"\n",
    "    except ValueError:\n",
    "        w_str = \"Wilcoxon skipped (all diffs zero)\"\n",
    "    print(f\"\\n=== Paired tests across runs ({metric}) ===\")\n",
    "    print(f\"Observed mean diff (kNN - Tree): {diff.mean():.4f} ± {diff.std(ddof=1):.4f}\")\n",
    "    print(f\"Paired t-test: t={t.statistic:.3f}, p={t.pvalue:.3e}\")\n",
    "    print(f\"Wilcoxon: {w_str}\")\n",
    "\n",
    "# =====================================================\n",
    "# 12) McNemar, permutation, and bootstrap on final test\n",
    "# =====================================================\n",
    "# McNemar on the COMMON final test split\n",
    "try:\n",
    "    from statsmodels.stats.contingency_tables import mcnemar\n",
    "    y_pred_knn_final  = final_knn[\"yhat\"]\n",
    "    y_pred_tree_final = final_tree[\"yhat\"]\n",
    "    correct_knn  = (y_pred_knn_final == y_test).astype(int)\n",
    "    correct_tree = (y_pred_tree_final == y_test).astype(int)\n",
    "    b01 = np.sum((correct_knn == 0) & (correct_tree == 1))  # knn wrong, tree right\n",
    "    b10 = np.sum((correct_knn == 1) & (correct_tree == 0))  # knn right, tree wrong\n",
    "    table = [[0, b01],\n",
    "             [b10, 0]]\n",
    "    mc = mcnemar(table, exact=True)\n",
    "    print(\"\\n=== McNemar’s test (final test split) ===\")\n",
    "    print(f\"b01={b01}, b10={b10}, statistic={mc.statistic}, p-value={mc.pvalue:.3e}\")\n",
    "except Exception as e:\n",
    "    print(\"\\n[McNemar skipped] Install statsmodels or check inputs:\", e)\n",
    "\n",
    "# Permutation test (accuracy diff) on final test split\n",
    "from scipy.stats import permutation_test\n",
    "acc_knn  = final_knn[\"accuracy\"]\n",
    "acc_tree = final_tree[\"accuracy\"]\n",
    "\n",
    "def acc_diff(x, y):\n",
    "    return accuracy_score(y_test, x) - accuracy_score(y_test, y)\n",
    "\n",
    "res = permutation_test((y_pred_knn_final, y_pred_tree_final), acc_diff,\n",
    "                       n_resamples=2000, alternative='two-sided', random_state=RANDOM_SEED+3)\n",
    "print(\"\\n=== Permutation test (accuracy, final test split) ===\")\n",
    "print(f\"Observed diff: {acc_knn - acc_tree:.4f}\")\n",
    "print(f\"p-value: {res.pvalue:.3e}\")\n",
    "\n",
    "# Bootstrap CI for accuracy difference (final test split)\n",
    "rng_boot = np.random.default_rng(RANDOM_SEED + 4)\n",
    "B = 5000\n",
    "acc_diffs = []\n",
    "n = len(y_test)\n",
    "y_test_np = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "y_knn_np  = np.asarray(y_pred_knn_final)\n",
    "y_tree_np = np.asarray(y_pred_tree_final)\n",
    "\n",
    "for _ in range(B):\n",
    "    idx = rng_boot.integers(0, n, size=n)\n",
    "    acc_knn_b  = accuracy_score(y_test_np[idx], y_knn_np[idx])\n",
    "    acc_tree_b = accuracy_score(y_test_np[idx], y_tree_np[idx])\n",
    "    acc_diffs.append(acc_knn_b - acc_tree_b)\n",
    "\n",
    "ci_low, ci_high = np.percentile(acc_diffs, [2.5, 97.5])\n",
    "print(\"\\n=== Bootstrap 95% CI for accuracy diff (kNN - Tree, final test split) ===\")\n",
    "print(f\"[{ci_low:.4f}, {ci_high:.4f}]\")\n",
    "\n",
    "# # ======================================\n",
    "# # 13) (Optional) Inspect top kNN configs\n",
    "# # ======================================\n",
    "# knn_cv = pd.DataFrame(knn_grid.cv_results_).sort_values(\"mean_test_score\", ascending=False)\n",
    "# cols_knn = [\"mean_test_score\",\"std_test_score\",\"param_n_neighbors\",\"param_weights\",\"param_metric\",\"param_p\"]\n",
    "# print(\"\\nTop kNN configs:\\n\", knn_cv[[c for c in cols_knn if c in knn_cv.columns]].head(10))\n",
    "\n",
    "# # And top tree configs (if desired)\n",
    "# tree_cv = pd.DataFrame(tree_rand.cv_results_).sort_values(\"mean_test_score\", ascending=False)\n",
    "# cols_tree = [\"mean_test_score\",\"std_test_score\",\"param_criterion\",\"param_max_depth\",\"param_min_samples_split\",\n",
    "#              \"param_min_samples_leaf\",\"param_max_features\",\"param_ccp_alpha\",\"param_class_weight\"]\n",
    "# print(\"\\nTop Tree configs:\\n\", tree_cv[cols_tree].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90439106-5a44-4fc7-9838-eaefe17c7c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating performace of k=5, k=7\n",
    "knn_k5 = KNeighborsClassifier(n_neighbors=5, algorithm=\"brute\", weights=\"distance\", metric=\"minkowski\", p=1)\n",
    "knn_k7 = KNeighborsClassifier(n_neighbors=7, algorithm=\"brute\", weights=\"distance\", metric=\"minkowski\", p=1)\n",
    "\n",
    "knn_k5.fit(X_knn_train, y_train)\n",
    "knn_k7.fit(X_knn_train, y_train)\n",
    "\n",
    "# Evaluate them on the final test split\n",
    "final_knn_k5 = evaluate(\"kNN (k=5)\", knn_k5, X_knn_test, y_test)\n",
    "final_knn_k7 = evaluate(\"kNN (k=7)\", knn_k7, X_knn_test, y_test)\n",
    "\n",
    "print(\"\\n== Final test (common split, extra k values) ==\")\n",
    "for res in [final_knn, final_knn_k5, final_knn_k7, final_tree]:\n",
    "    print(f\"{res['name']}: Acc={res['accuracy']:.4f}, \"\n",
    "          f\"Prec={res['precision']:.4f}, \"\n",
    "          f\"Rec={res['recall']:.4f}, \"\n",
    "          f\"F1={res['f1']:.4f}\")\n",
    "\n",
    "cv_knn_k5 = cross_validate(knn_k5, X_knn_train, y_train,\n",
    "                           cv=CV_FOLDS, scoring=scorers, n_jobs=-1)\n",
    "cv_knn_k7 = cross_validate(knn_k7, X_knn_train, y_train,\n",
    "                           cv=CV_FOLDS, scoring=scorers, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "541114f9-a5d1-404d-9f75-dfb0d65f757a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== kNN (k=5) CV Results (mean ± std across 10 folds) ===\n",
      "                    mean     std\n",
      "fit_time          0.5009  0.0155\n",
      "score_time      791.6071  0.5828\n",
      "test_accuracy     0.9324  0.0012\n",
      "test_precision    0.9323  0.0012\n",
      "test_recall       0.9324  0.0012\n",
      "test_f1           0.9323  0.0012\n",
      "\n",
      "=== kNN (k=7) CV Results (mean ± std across 10 folds) ===\n",
      "                    mean     std\n",
      "fit_time          0.5312  0.0214\n",
      "score_time      790.5449  0.5458\n",
      "test_accuracy     0.9312  0.0014\n",
      "test_precision    0.9311  0.0015\n",
      "test_recall       0.9312  0.0014\n",
      "test_f1           0.9310  0.0014\n"
     ]
    }
   ],
   "source": [
    "def summarize_cv(cv_res, name):\n",
    "    df = pd.DataFrame(cv_res)\n",
    "    mean_std = df.agg([\"mean\",\"std\"]).round(4).T\n",
    "    print(f\"\\n=== {name} CV Results (mean ± std across {CV_FOLDS} folds) ===\")\n",
    "    print(mean_std)\n",
    "\n",
    "summarize_cv(cv_knn_k5, \"kNN (k=5)\")\n",
    "summarize_cv(cv_knn_k7, \"kNN (k=7)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18ed84c6-ac3f-42d4-a73e-c25aebe96b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Global Mean ± Std across runs ===\n",
      "      accuracy         precision          recall              f1        \n",
      "          mean     std      mean     std    mean     std    mean     std\n",
      "model                                                                   \n",
      "Tree    0.8229  0.0043    0.8226  0.0044  0.8229  0.0043  0.8225  0.0044\n",
      "kNN     0.8636  0.0023    0.8630  0.0023  0.8636  0.0023  0.8631  0.0023\n",
      "\n",
      "=== Per-class Mean ± Std across runs ===\n",
      "            precision          recall              f1        \n",
      "                 mean     std    mean     std    mean     std\n",
      "model class                                                  \n",
      "Tree  1        0.8044  0.0072  0.8306  0.0102  0.8173  0.0060\n",
      "      2        0.8511  0.0068  0.8421  0.0068  0.8465  0.0040\n",
      "      3        0.8142  0.0131  0.8233  0.0155  0.8186  0.0106\n",
      "      4        0.7122  0.0466  0.6732  0.0619  0.6908  0.0467\n",
      "      5        0.6187  0.0287  0.5267  0.0324  0.5685  0.0263\n",
      "      6        0.6872  0.0183  0.6320  0.0266  0.6581  0.0186\n",
      "      7        0.8575  0.0147  0.7965  0.0107  0.8258  0.0095\n",
      "kNN   1        0.8719  0.0036  0.8566  0.0047  0.8642  0.0036\n",
      "      2        0.8776  0.0029  0.8955  0.0026  0.8865  0.0020\n",
      "      3        0.8268  0.0068  0.8361  0.0095  0.8314  0.0051\n",
      "      4        0.7126  0.0310  0.6420  0.0388  0.6743  0.0231\n",
      "      5        0.6823  0.0233  0.5873  0.0243  0.6310  0.0200\n",
      "      6        0.6889  0.0153  0.6710  0.0162  0.6797  0.0106\n",
      "      7        0.8833  0.0129  0.8647  0.0118  0.8738  0.0089\n"
     ]
    }
   ],
   "source": [
    "N_RUNS = 15\n",
    "RUN_SUBSET_SIZE = 75_000  # number of samples per run\n",
    "TEST_SIZE = 0.30\n",
    "\n",
    "rng_global = np.random.default_rng(42)\n",
    "\n",
    "results = []\n",
    "per_class_results = []\n",
    "\n",
    "for run in range(1, N_RUNS + 1):\n",
    "    subset_idx = rng_global.choice(len(y), size=RUN_SUBSET_SIZE, replace=False)\n",
    "    X_knn_sub, X_tree_sub, y_sub = (\n",
    "        X_knn_df.iloc[subset_idx],\n",
    "        X_tree_df.iloc[subset_idx],\n",
    "        y.iloc[subset_idx]\n",
    "    )\n",
    "\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=TEST_SIZE, random_state=run)\n",
    "    (tr, te), = sss.split(X_knn_sub, y_sub)\n",
    "\n",
    "    X_knn_tr, X_knn_te = X_knn_sub.iloc[tr], X_knn_sub.iloc[te]\n",
    "    X_tree_tr, X_tree_te = X_tree_sub.iloc[tr], X_tree_sub.iloc[te]\n",
    "    y_tr, y_te = y_sub.iloc[tr], y_sub.iloc[te]\n",
    "\n",
    "    knn_run  = KNeighborsClassifier(algorithm=\"brute\", **{k: v for k, v in knn_grid.best_params_.items() if k != \"algorithm\"})\n",
    "    tree_run = DecisionTreeClassifier(random_state=run, **tree_rand.best_params_)\n",
    "\n",
    "    knn_run.fit(X_knn_tr, y_tr);  y_knn = knn_run.predict(X_knn_te)\n",
    "    tree_run.fit(X_tree_tr, y_tr); y_tree = tree_run.predict(X_tree_te)\n",
    "\n",
    "    for model, y_pred in [(\"kNN\", y_knn), (\"Tree\", y_tree)]:\n",
    "        results.append({\n",
    "            \"run\": run,\n",
    "            \"model\": model,\n",
    "            \"accuracy\":  accuracy_score(y_te, y_pred),\n",
    "            \"precision\": precision_score(y_te, y_pred, average=\"weighted\", zero_division=0),\n",
    "            \"recall\":    recall_score(y_te, y_pred, average=\"weighted\", zero_division=0),\n",
    "            \"f1\":        f1_score(y_te, y_pred, average=\"weighted\", zero_division=0),\n",
    "        })\n",
    "\n",
    "        report = classification_report(y_te, y_pred, zero_division=0, output_dict=True)\n",
    "        for label, vals in report.items():\n",
    "            if label not in [\"accuracy\", \"macro avg\", \"weighted avg\"]:\n",
    "                per_class_results.append({\n",
    "                    \"run\": run,\n",
    "                    \"model\": model,\n",
    "                    \"class\": label,\n",
    "                    \"precision\": vals[\"precision\"],\n",
    "                    \"recall\": vals[\"recall\"],\n",
    "                    \"f1\": vals[\"f1-score\"],\n",
    "                    \"support\": vals[\"support\"]\n",
    "                })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_per_class = pd.DataFrame(per_class_results)\n",
    "\n",
    "# --- Aggregate Mean ± Std\n",
    "summary_global = (\n",
    "    df_results\n",
    "    .groupby(\"model\")[[\"accuracy\",\"precision\",\"recall\",\"f1\"]]\n",
    "    .agg([\"mean\",\"std\"])\n",
    "    .round(4)\n",
    ")\n",
    "print(\"\\n=== Global Mean ± Std across runs ===\")\n",
    "print(summary_global)\n",
    "\n",
    "summary_per_class = (\n",
    "    df_per_class\n",
    "    .groupby([\"model\",\"class\"])[[\"precision\",\"recall\",\"f1\"]]\n",
    "    .agg([\"mean\",\"std\"])\n",
    "    .round(4)\n",
    ")\n",
    "print(\"\\n=== Per-class Mean ± Std across runs ===\")\n",
    "print(summary_per_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
